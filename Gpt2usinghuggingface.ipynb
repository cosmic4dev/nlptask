{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JkxrKwrWU1B",
        "outputId": "499a92c6-9a64-46f0-ad1f-9afb8667db70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer\n",
            "└ wte\n",
            "└ wpe\n",
            "└ drop\n",
            "└ h\n",
            "│  └ 0\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 1\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 2\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 3\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 4\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 5\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 6\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 7\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 8\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 9\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 10\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 11\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "└ ln_f\n",
            "lm_head\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"└\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"│  └\", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"│  │  └\", sssub_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 생성해보기\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
        "outputs = generator(\n",
        "    text_inputs=\"weight training is\",\n",
        "    max_length=20,\n",
        "    num_return_sequences=3,\n",
        "    pad_token_id=generator.tokenizer.eos_token_id,\n",
        "    truncation=True\n",
        ")\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpoascQsXpkb",
        "outputId": "9323d405-aff5-473a-a81b-3c183bfee4b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'weight training is extremely popular. However, when I was studying in Berlin, I was not trained in'}, {'generated_text': 'weight training is a simple exercise. It is a short-term, low-fat, nutrient-'}, {'generated_text': 'weight training is a long term, relatively small procedure. Since most large bodybuilders will be the sole'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt-2를 텍스트 분류의 다운스트림 task에 적용하기\n",
        "!pip install --upgrade torch  # Upgrade torch to a version that includes DILL_AVAILABLE\n",
        "!pip install --upgrade torchdata # Upgrade torchdata to ensure compatibility with the latest torch version\n",
        "!pip install torchdata torchtext portalocker\n",
        "\n",
        "import torch\n",
        "from torchtext.datasets import CoLA\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collator(batch, tokenizer, device):\n",
        "    source, labels, texts = zip(*batch)\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
        "    return input_ids, attention_mask, labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaeD78PCYbJE",
        "outputId": "c2334ffc-3837-40b3-a239-dc1ca7d28dda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = list(CoLA(split=\"train\"))\n",
        "valid_data = list(CoLA(split=\"dev\"))\n",
        "test_data = list(CoLA(split=\"test\"))\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "epochs = 3\n",
        "batch_size = 16\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=lambda x: collator(x, tokenizer, device),\n",
        "    shuffle=True,\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)\n",
        ")\n",
        "\n",
        "print(\"Train Dataset Length :\", len(train_data))\n",
        "print(\"Valid Dataset Length :\", len(valid_data))\n",
        "print(\"Test Dataset Length :\", len(test_data))"
      ],
      "metadata": {
        "id": "cqUGOhgEZxWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "541ad4f7-f799-419b-d142-b08aaadf1d92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Length : 8550\n",
            "Valid Dataset Length : 526\n",
            "Test Dataset Length : 515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt-2 model 설정\n",
        "from torch import optim\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2).to(device)\n",
        "model.config.pad_token_id = model.config.eos_token_id #gpt-2에 토크나이저가 포함되어있지 않아 패딩 토큰으로 대체한다.\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDh8A83-ABhD",
        "outputId": "06bc59a8-2d38-4e71-cd5c-6cea241b6dd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt-2모델 학습 및 검증\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for input_ids, attention_mask, labels in dataloader:\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        val_loss, val_accuracy = 0.0, 0.0\n",
        "\n",
        "        for input_ids, attention_mask, labels in dataloader:\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to(\"cpu\").numpy()\n",
        "            accuracy = calc_accuracy(logits, label_ids)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_accuracy += accuracy\n",
        "\n",
        "    val_loss = val_loss/len(dataloader)\n",
        "    val_accuracy = val_accuracy/len(dataloader)\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check if the directory exists\n",
        "model_dir = \"../models\"\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)  # Create the directory if it does not exist\n",
        "\n",
        "# Now save the model\n",
        "model_path = os.path.join(model_dir, \"GPT2ForSequenceClassification.pt\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Saved the model weights at:\", model_path)\n",
        "best_loss = 10000\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"../models/GPT2ForSequenceClassification.pt\")\n",
        "        print(\"Saved the model weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lI0iGvjABWS",
        "outputId": "e131a5e6-5da5-47af-93ad-0fe91a5247ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the model weights at: ../models/GPT2ForSequenceClassification.pt\n",
            "Epoch 1: Train Loss: 0.4876 Val Loss: 0.4764 Val Accuracy 0.7768\n",
            "Saved the model weights\n",
            "Epoch 2: Train Loss: 0.3539 Val Loss: 0.4860 Val Accuracy 0.7938\n",
            "Epoch 3: Train Loss: 0.2507 Val Loss: 0.5211 Val Accuracy 0.7938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"gpt2\",\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "model.load_state_dict(torch.load(\"../models/GPT2ForSequenceClassification.pt\"))\n",
        "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_oUFyukCj_8",
        "outputId": "9583366c-8dfd-4629-8809-568030713eed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5528\n",
            "Test Accuracy: 0.7323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "data set size가 8,550개, 모델에 비해 상대적으로 적은 데이터셋을 사용했다.\n",
        "하지만 나름 높은 성능을 발휘, 이 모델이 작은 데이터셋에서도 일반화 성능을 갖고 있음을 추정해 볼 수 있었다."
      ],
      "metadata": {
        "id": "AlOqHuZVHc8r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEkDAoInIkGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}